# ğŸ¥ Skin Cancer Classification using Vision Transformers
### Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡ Ø³Ø±Ø·Ø§Ù† Ù¾ÙˆØ³Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vision Transformers Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ CNN Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª HAM10000

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org/)
[![Colab Ready](https://img.shields.io/badge/Colab-Notebook-orange?logo=google-colab)](https://colab.research.google.com/drive/1oKMqp_sJj6EixgB0ych7kypC-WU2BhAL?usp=sharing)
[![Demo](https://img.shields.io/badge/ğŸ”—-Live%20Demo-brightgreen)](http://skin-cancer-classifier.ir/)

## ğŸŒ Project Website  
- Experience the deployed model in real-time. Upload images and receive instant 7-class predictions with confidence scores.  
Ù…Ø¯Ù„ Ù…Ø³ØªÙ‚Ø±Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø²Ù†Ø¯Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯. ØªØµØ§ÙˆÛŒØ± Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Û·Ú©Ù„Ø§Ø³Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¢Ù†ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯

ğŸ‘‰ **[Launch Web Application | Ø§Ø¬Ø±Ø§ÛŒ ÙˆØ¨ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†](http://skin-cancer-classifier.ir/)**

---

## ğŸ¥ Project Video Presentation   
- A comprehensive walkthrough covering motivation, research inspiration, implementation details, training pipeline, results analysis, and future directions.  
Ø§Ø±Ø§Ø¦Ù‡ Ø¬Ø§Ù…Ø¹ Ø´Ø§Ù…Ù„ Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ØŒ Ø§Ù„Ù‡Ø§Ù… ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒØŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒØŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¢Ù…ÙˆØ²Ø´ØŒ ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ùˆ Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡

ğŸ‘‰ **[Watch Video Presentation (Google Drive) | Ù…Ø´Ø§Ù‡Ø¯Ù‡ ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ](https://drive.google.com/your-video-link-here)**

---
## ğŸ“ Trained Model

Download Trained Model: [best_model.pth](https://drive.google.com/file/d/1ImBtWSDCXjXNwDS29bcagWJbgllbVpgt/view?usp=sharing) *(Google Drive - Û²Û´Û· Ù…Ú¯Ø§Ø¨Ø§ÛŒØª)

---

## ğŸ–¼ï¸Image Samples

Download Image Samples: [skin_cancer_samples.zip](https://drive.google.com/drive/folders/1JH_-0GlJYRCKCWruh0HLw2dexzVVPAjP?usp=sharing) *(Google Drive)*


## ğŸ“‘ Table of Contents | 
- [ğŸŒ Project Website ](#-project-website)
- [ğŸ¥ Project Video Presentation](#-project-video-presentation)
- [ğŸ“ Trained Model](#-trained-model)
- [ğŸ“„ Research Inspiration](#-research-inspiration)
- [ğŸ“‹ Project Context](#-project-context)
- [ğŸ“Š HAM10000 Dataset Overview](#-ham10000-dataset-overview)
- [ğŸ§  Model Architecture](#-model-architecture)
- [âœ¨ Key Features](#-key-features)
- [ğŸ“¥ Installation & Setup](#-installation--setup)
- [ğŸƒ Project Usage](#-projectusage)
- [ğŸ“Š Results & Analysis](#-results--analysis)
- [ğŸ”¬ Technical Deep Dive](#-technical-deep-dive)
- [ğŸš€ Project Demo ](#-project-demo)
- [ğŸ† Achievements & Impact](#-achievements--impact)
- [ğŸ™ Acknowledgments](#-acknowledgments)
- [ğŸ“¬ Contact](#-contact)
- [ğŸ“œ License](#-license)

---

## ğŸ“„ Research Inspiration  
This project is directly inspired by the peer-reviewed paper published in *Information* (MDPI):

> **Multi-Class Skin Cancer Classification Using Vision Transformer Networks and Convolutional Neural Network-Based Pre-Trained Models**  
> Muhammad Asad ArshedÂ¹Â²âº, Shahzad MumtazÂ³, Muhammad IbrahimÂ², Saeed AhmedÂ¹, Muhammad Tahirâ´âµ, Muhammad Shafiâ¶  
> *Information 2023, 14(7), 415* | DOI: [10.3390/info14070415](https://doi.org/10.3390/info14070415) | Published: 18 July 2023

**Key Findings / ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ù‚Ø§Ù„Ù‡:**
- Vision Transformer (ViT) achieved **92.14% accuracy**, outperforming 11 CNN-based transfer learning models.  
- Superior performance in precision (+11.11%), recall, and F1-score compared to ResNet50.  
- Effective handling of severe class imbalance through targeted augmentation and weighted loss.  

This implementation faithfully reproduces the core methodology while optimizing for educational and deployment purposes.  
Ø§ÛŒÙ† Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±ÙˆØ´ Ø§ØµÙ„ÛŒ Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§Ø²ØªÙˆÙ„ÛŒØ¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ù…Ù„ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª

---

## ğŸ“‹ Project Context 
**University:** Islamic Azad University, Science and Research Branch, Tehran | Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¢Ø²Ø§Ø¯ Ø§Ø³Ù„Ø§Ù…ÛŒ ÙˆØ§Ø­Ø¯ Ø¹Ù„ÙˆÙ… Ùˆ ØªØ­Ù‚ÛŒÙ‚Ø§Øª
**Course:** Multimedia Communications | Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ú†Ù†Ø¯Ø±Ø³Ø§Ù†Ù‡â€ŒØ§ÛŒ  
**Term:** Fall 1404 (2025â€“2026) | Ù¾Ø§ÛŒÛŒØ² Û±Û´Û°Û´  
**Supervisor:** Professor Mehdi Eslami | Ø§Ø³ØªØ§Ø¯ Ù…Ù‡Ø¯ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ  
**Objective:** Explore advanced deep learning architectures in medical imaging and multimedia systems for real-world healthcare applications.  
Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ø¯Ø± ØªØµÙˆÛŒØ±Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ù¾Ø²Ø´Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø³Ù„Ø§Ù…Øª Ùˆ Ù¾Ø²Ø´Ú©ÛŒ Ø§Ø² Ø±Ø§Ù‡ Ø¯ÙˆØ±

---

## ğŸ“Š HAM10000 Dataset Overview
The **HAM10000** dataset contains 10,015 high-quality dermatoscopic images labeled across 7 diagnostic categories, making it one of the largest publicly available skin lesion datasets.

| Class | Diagnosis (EN)                     | ØªØ´Ø®ÛŒØµ (FA)                     | Count  | %      | Clinical Significance                  |
|-------|------------------------------------|--------------------------------|--------|--------|----------------------------------------|
| nv    | Melanocytic Nevi                   | Ø®Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù„Ø§Ù†ÙˆØ³ÛŒØªÛŒÚ©            | 6,705  | 66.95% | Ø®ÙˆØ´â€ŒØ®ÛŒÙ… (Ø´Ø§ÛŒØ¹â€ŒØªØ±ÛŒÙ†)                   |
| mel   | Melanoma                           | Ù…Ù„Ø§Ù†ÙˆÙ…Ø§                        | 1,113  | 11.11% | Ø¨Ø¯Ø®ÛŒÙ… (Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø®Ø·Ø± Ù…Ø±Ú¯)             |
| bkl   | Benign Keratosis-like Lesions      | Ø¶Ø§ÛŒØ¹Ø§Øª Ú©Ø±Ø§ØªÙˆØ²ÛŒ Ø®ÙˆØ´â€ŒØ®ÛŒÙ…        | 1,099  | 10.97% | Ø®ÙˆØ´â€ŒØ®ÛŒÙ…                               |
| bcc   | Basal Cell Carcinoma               | Ú©Ø§Ø±Ø³ÛŒÙ†ÙˆÙ… Ø³Ù„ÙˆÙ„ Ø¨Ø§Ø²Ø§Ù„           | 514    | 5.13%  | Ø¨Ø¯Ø®ÛŒÙ…                                 |
| akiec | Actinic Keratoses                  | Ú©Ø±Ø§ØªÙˆØ² Ø§Ú©ØªÛŒÙ†ÛŒÚ©                | 327    | 3.27%  | Ù¾ÛŒØ´â€ŒØ³Ø±Ø·Ø§Ù†ÛŒ                            |
| vasc  | Vascular Lesions                   | Ø¶Ø§ÛŒØ¹Ø§Øª Ø¹Ø±ÙˆÙ‚ÛŒ                   | 142    | 1.42%  | Ø®ÙˆØ´â€ŒØ®ÛŒÙ…                               |
| df    | Dermatofibroma                     | Ø¯Ø±Ù…Ø§ØªÙˆÙÛŒØ¨Ø±ÙˆÙ…                   | 115    | 1.15%  | Ø®ÙˆØ´â€ŒØ®ÛŒÙ…                               |

**Source / Ù…Ù†Ø¨Ø¹:** [Kaggle - Skin Cancer MNIST: HAM10000](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000)

---

## ğŸ§  Model Architecture  
### Primary Model / Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ: Vision Transformer (ViT-Base)
- Patch size: 16Ã—16 pixels
- Encoder layers: 12
- Hidden dimension: 768
- Multi-head attention: 12 heads
- Pre-trained on ImageNet-21k
- End-to-end fine-tuning

### Baseline Models / Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ (Transfer Learning)
- ResNet series (18/50/101/152)
- DenseNet series (121/169/201)
- EfficientNet family (B0â€“B4)
- VGG16/19 with Batch Normalization

**Training Strategy / Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¢Ù…ÙˆØ²Ø´ (Two-Phase):**
1. Feature extraction with frozen backbone
2. Full fine-tuning with discriminative learning rates

---

## âœ¨ Key Features  
- **State-of-the-Art Performance**: Up to 92.14% accuracy as validated in research | Ø¯Ù‚Øª ØªØ§ Û¹Û².Û±Û´Ùª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§Ù„Ù‡ Ù…Ø±Ø¬Ø¹
- **Robust Imbalance Mitigation**: Weighted loss functions, focal loss, and strategic oversampling | Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
- **Medical-Grade Augmentation**: Albumentations-based pipeline including CLAHE, elastic transforms, and color jittering | Ø¢Ú¯Ù…Ù†ØªÛŒØ´Ù† ØªØ®ØµØµÛŒ Ù¾Ø²Ø´Ú©ÛŒ
- **Comprehensive Metrics Suite**: Full evaluation with accuracy, precision, recall, F1-score, confusion matrix, and per-class analysis | Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ú©Ø§Ù…Ù„ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
- **Real-Time Web Deployment**: Responsive Flask application with drag-and-drop interface | ÙˆØ¨ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¢Ù†ÛŒ
- **Model Interpretability**: Confidence scoring and prediction visualization | Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙØ³ÛŒØ± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§
- **Full Reproducibility**: Complete Google Colab notebook with seeded randomness | ØªÚ©Ø±Ø§Ø±Ù¾Ø°ÛŒØ±ÛŒ Ú©Ø§Ù…Ù„
- **Extensible Framework**: Modular design for rapid experimentation with new architectures | Ú†Ø§Ø±Ú†ÙˆØ¨ Ù…Ø¯ÙˆÙ„Ø§Ø± Ùˆ Ù‚Ø§Ø¨Ù„ Ú¯Ø³ØªØ±Ø´

---

## ğŸ“¥ Installation & Setup
### Prerequisites / Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§
- Python 3.8 or higher
- NVIDIA GPU recommended (free tier available on Google Colab)

### Quick Start / Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹ (Google Colab â€“ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡)
1. Open the notebook: [Colab Link](https://colab.research.google.com/drive/1oKMqp_sJj6EixgB0ych7kypC-WU2BhAL?usp=sharing)
2. Mount Google Drive
3. Execute cells sequentially

### Local Installation / Ù†ØµØ¨ Ù…Ø­Ù„ÛŒ
```bash
git clone https://github.com/yourusername/skin-cancer-vit-ham10000.git
cd skin-cancer-vit-ham10000

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt

### Dataset Preparation / Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø³Øª
```bash
kaggle datasets download -d kmader/skin-cancer-mnist-ham10000
unzip skin-cancer-mnist-ham10000.zip -d data/
```Ù¾
---

##  Project Usage  
### Model Training / Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
```bash
python train.py --model vit --epochs 50 --batch-size 32 --lr 1e-3 --use-augmentation
```

### Model Evaluation / Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
```bash
python evaluate.py --weights models/best_vit.pth --generate-plots
```

### Single Image Inference / Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± ØªÚ©ÛŒ
```python
from src.inference import SkinCancerClassifier

classifier = SkinCancerClassifier("models/best_vit.pth")
result = classifier.predict("samples/example_lesion.jpg")
print(f"Predicted: {result['class']} | Confidence: {result['confidence']:.2%}")
```

### Launch Web Application / Ø§Ø¬Ø±Ø§ÛŒ ÙˆØ¨ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†
```bash
cd web_app
python app.py
# Access at http://localhost:5000
```

---

## ğŸ“Š Results & Analysis   
### Benchmark Performance (Original Paper) / Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù†Ú†Ù…Ø§Ø±Ú© (Ù…Ù‚Ø§Ù„Ù‡ Ø§ØµÙ„ÛŒ)
| Model               | Accuracy | Precision | Recall  | F1-Score |
|---------------------|----------|-----------|---------|----------|
| **Vision Transformer** | **92.14%** | **92.61%** | **92.14%** | **92.17%** |
| ResNet152           | 88.21%   | 88.50%    | 88.21%  | 88.35%   |
| DenseNet201         | 89.43%   | 89.70%    | 89.43%  | 89.56%   |
| VGG19               | 85.12%   | 85.40%    | 85.12%  | 85.26%   |

### Our Implementation Results / Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§ (ResNet18 Ø³Ø¨Ú© â€“ Û²Û°Ùª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)
- Overall Test Accuracy: ~75%
- Excellent performance on dominant class `nv` (93.4%)
- Perfect on `vasc` (100%)
- Promising on critical class `mel` (54.5%) â€“ further improvement possible with full dataset

#### Visual Results / Ù†ØªØ§ÛŒØ¬ Ø¨ØµØ±ÛŒ
**Confusion Matrix | Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ**  
![Confusion Matrix](results/confusion_matrix.png)

**Random Test Predictions | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØµØ§Ø¯ÙÛŒ Ø±ÙˆÛŒ ØªØµØ§ÙˆÛŒØ± ØªØ³Øª**  
![Random Predictions](results/random_predictions.png)

---

## ğŸ”¬ Technical Deep Dive   
### Data Pipeline / Ø®Ø· Ù„ÙˆÙ„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡
- Image resizing: 224Ã—224 (ViT) / 128Ã—128 (lightweight models)
- Normalization using ImageNet statistics
- Advanced augmentation via Albumentations (rotation, flip, brightness/contrast, CLAHE, elastic deformation)

### Training & Optimization / Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
- Loss function: Weighted CrossEntropyLoss + optional Focal Loss
- Optimizer: AdamW with weight decay
- Learning rate scheduler: CosineAnnealingWarmRestarts
- Mixed precision training (AMP) and gradient clipping
- Early stopping and model checkpointing

### Reproducibility & Best Practices / ØªÚ©Ø±Ø§Ø±Ù¾Ø°ÛŒØ±ÛŒ Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§
- Fixed random seeds across NumPy, PyTorch, and CUDA
- Deterministic operations enabled
- Dependency versioning via `requirements.txt`

---
## ğŸš€ Project Demo 

![Class Distribution](https://github.com/user-attachments/assets/fc8151f3-dae2-43d8-9594-912223dd51fb)

---

## ğŸ† Achievements & Impact    
- Successful reproduction of state-of-the-art Vision Transformer results in medical imaging domain
- Practical, user-friendly web deployment for real-world testing
- Significant educational contribution to multimedia AI applications in healthcare
- Solid foundation for future telemedicine and mobile diagnostic tools

---

## ğŸ™ Acknowledgments 
We extend sincere gratitude to the authors of the original research paper for their pioneering work and open-access publication.

Special thanks to the creators of the HAM10000 dataset and the global medical AI research community for making such valuable resources publicly available.

---

## ğŸ“¬ Contact

ğŸ“§ [meli.sadegh@gmail.com](mailto:meli.sadegh@gmail.com)

---

## ğŸ“œ License 
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for full details.
